<!DOCTYPE html>
<html>
<body>
  <h1>Methods:</h1>
  <h3>Data scraping and API Methods</h3>
  <p> We first accessed the <a href="https://openlibrary.org/developers/dumps">Open Library Data Dumps</a>, which provides metadata records and Internet Archive identifiers for a substantial subset (roughly 4 million books out of 8 million total) of the overall IA collection. </p>
  <p> We then used the IA identifiers to programatically query the Internet Archive API using the <a href="https://archive.org/developers/quick-start-pip.html">IA python package</a>, keeping the metadata fields relevant for the creative process.</p>
  
  <p>Metadata key</a>
  <ul>
    <li>ID: Internet Archive unique identifier</li>
    <li>Title</li>
    <li>Author</li>
     <li>Camera: tech spec of camera used to scan</li>
     <li>Contributor: Organization owner who provided book</li>
     <li>publish_date: date original work published</li>
     <li>language: language of original book</li>
     <li>operator: name of worker performing scan</li>
     <li>ppi: resolution of scan</li>
     <li>repub_state: unknown</li>
     <li>scanner: machine used to perform scan</li>
     <li>scanningcenter: location scan performed</li>
     <li>sponsor: entity paying for scan</li>
     <li>scandate: date scanned (deprecated, use date)</li>
     <li>imagecount: number of pages</li>
     <li>republisher_operator: worker performing republishing (editing, quality control, formatting)</li>
     <li>republisher_date: day republishing labor performed</li>
    <li>republisher_time: time republishing labor performed</li>
    <li>scanfee: amount charged for scanning</li>
    <li>sponsordate: unknown</li>
    <li>ocr_converted: software used to perform OCR on scan</li>
    <li>page_number_confidence: unknown</li>
    <li>search_date: date added to IA records</li>
    <li>date: cleaned and formatted date</li>
  
  </ul>
  <p>Complete and processed data files are available at <a href="https://uofi.box.com/s/2hvihu1tp4t2m0sapdb7wbjkl2zvpudf">this Box site</a>. </p>
    <ul>
      <li>IA_metadata_full.csv: complete scraped metadata for 3 million books</li>
      <li>centers_per_year.csv: books scanned at each center per month</li>
      <li>per_center_stats.csv: finalized list of geocoded centers with various aggregate statistics</li>
  </ul>
  
  <p>Jupyter notebooks used to scrape, clean, and create visualizations along with our website code are available at <a href="https://github.com/scanninglabor/IAScanningLabor">our Github repo</a></p>
  
  <h3>Mapping Methods</h3>
  
  <h3>Oral History Methods</h3>
  <p>Initially, our goal for this project was to include oral histories of scan operators at each of the scanning centers. To do so, we developed a series of questions found here: <a href="https://docs.google.com/document/d/18msJjzixYps1LA95IArxlGpROqFgDQLf88edpxUHlvQ/edit?usp=sharing">DH-IA-oral history questions</a> and planned to conduct one-hour oral interviews to capture the day-to-day experience of scanning for IA. </p>
  <p> We scraped over 500 emails from the metadata and reached out individually to 25 of those people. Unfortunately, we had trouble connecting with any of them - almost all of the emails bounced back. This highlights the high turnover rate of scanners at IA that contributes to the invisibility of these workers. We did receive one reply from a scan operator: “Thank you for considering me for this project. Unfortunately I don't feel I would be a good fit at this time. Please contact Chris Freeland at chrisfreeland@archive.org. Chris is our PR representative. I'm sure they will be able to help you.” We reached out to Chris Freeland at Internet Archive but did not receive a reply. </p>
  <p> Pivoting our approach, we created a google survey to send out oral history questions via email. We felt a google survey would lead to more responses as it takes less time from interviewees and is completely anonymous. We wanted to be cognizant of the extra time and unpaid labor we would be asking of these workers, so the survey is only 13 questions and none of them are required. We were able to send this survey to all 500 of the email addresses that were in the metadata, so we had a broader reach and higher likelihood of connecting with workers who were interested and emails were still active. We created a <a href="https://docs.google.com/forms/d/e/1FAIpQLScYci2RBW5-j2baAs8BRS7Xdxgz3PKrzzo6UygPXrIRgduHqQ/viewform?usp=sf_link">Google forms survey</a>. So far we’ve only received three responses and many bounced back emails. </p>
  <p> Beyond gathering stories and anecdotes through oral history and survey, we also sought out pre-existing worker narratives on glassdoor. From our experience, it seems crucial to approach oral history more intentionally and slowly, to be realisitic about the commitment to relationship building it entials. </p>
  <p> Another aspect of oral history in our project was to meet with several non-scanning staff at the Internet Archive (although two of the people we interviewed had started as scanners). We conducted two hour long interviews to understand the workflow of scanning centers, better understand our findings in the metadata, and get contacts for further interviews. </p>
  <p> While IA middle management were initially willing to meet with us and interview them for the project, they refused to go forward with the project after we sent out our survey to IA scanning center workers. After sending the survey, we received this email from an IA staff member: “I'm glad our conversation was helpful for your project. At this point, we have participated as an organization to the extent that we are comfortable. If you have any further inquiries, please direct them to me.” </p>
  <p> </p>
  </body>
</html>
